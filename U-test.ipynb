{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mannwhitneyu\n",
    "# 讀取數據\n",
    "file_path = \"F:\\\\All data\\\\Patient_Signal\\\\PPG.csv\"\n",
    "data = pd.read_csv(file_path, header=None)\n",
    "data.columns = ['Name', 'i', 'Bad', 'hands', 'label', 'systolic peak', 'Diastolic peak', 'Cardiac cycle', \n",
    "                'Cycle Area', 'SSI', 'Peak to Valley', 'Systolic peak y', 'Delta_T', \n",
    "                '1st Derivative cycle', '1st Derivative peak', 'Ratio_BA', 'Ratio_CA', 'Ratio_DA', \n",
    "                'Ratio_BDCE_A', 'Ratio_CDB_A']\n",
    "\n",
    "# 提取特徵和標籤\n",
    "X = data.iloc[:, 5:]  # 特徵列\n",
    "y = data['label']     # 標籤\n",
    "\n",
    "# 進行曼惠特尼 U 檢定\n",
    "significant_features = []\n",
    "p_values = {}\n",
    "\n",
    "for column in X.columns:\n",
    "    group_0 = X[y == 0][column]\n",
    "    group_1 = X[y == 1][column]\n",
    "    stat, p_value = mannwhitneyu(group_0, group_1, alternative='two-sided')\n",
    "    p_values[column] = p_value\n",
    "    if p_value < 0.05:\n",
    "        significant_features.append(column)\n",
    "\n",
    "# 輸出顯著性特徵及其 p-value\n",
    "print(\"顯著性特徵及其 p-value：\")\n",
    "for feature, p_value in p_values.items():\n",
    "    if feature in significant_features:\n",
    "        print(f\"{feature}: p-value = {p_value:.4f}\")\n",
    "\n",
    "# 使用顯著性特徵進行分類\n",
    "X_significant = X[significant_features]\n",
    "\n",
    "info_columns = data[['Name', 'i', 'Bad', 'hands']]\n",
    "X = data.iloc[:, 5:]  # 特徵列\n",
    "y = data['label']     # 標籤\n",
    "\n",
    "# 分割訓練和測試集\n",
    "X_train, X_test, y_train, y_test, info_train, info_test = train_test_split(X, y, info_columns, test_size=0.3, random_state=42)\n",
    "\n",
    "# 特徵標準化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 特徵標準化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製混淆矩陣\n",
    "def plot_confusion_matrix(conf_matrix, title='Confusion Matrix'):\n",
    "    plt.figure(figsize=(5, 5), dpi=120)\n",
    "    plt.imshow(conf_matrix, cmap='summer')\n",
    "    plt.colorbar()\n",
    "\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            plt.text(j, i, str(conf_matrix[i, j]), fontsize=12,\n",
    "                     horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "\n",
    "    \n",
    "    plt.xticks(np.arange(0, 2), ['Predicted 0', 'Predicted 1'])\n",
    "    plt.yticks(np.arange(0, 2), ['Actual 0', 'Actual 1'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算性能指標\n",
    "def calculate_metrics(conf_matrix):\n",
    "    tp = conf_matrix[0, 0]\n",
    "    fn = conf_matrix[0, 1]\n",
    "    fp = conf_matrix[1, 0]\n",
    "    tn = conf_matrix[1, 1]\n",
    "    accuracy = (tp + tn) / (tp + fn + fp + tn) if (tp + fn + fp + tn) != 0 else 0\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "    f1_score = 2 * (precision * sensitivity) / (precision + sensitivity) if (precision + sensitivity) != 0 else 0\n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": round(accuracy,3),\n",
    "        \"Sensitivity (Recall)\": round(sensitivity,3),\n",
    "        \"Specificity\": round(specificity,3),\n",
    "        \"Precision\": round(precision,3),\n",
    "        \"F1-Score\": round(f1_score,3)\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存結果到 CSV\n",
    "def save_results_to_csv(filename, info, y_test, y_pred):\n",
    "    new_data = pd.DataFrame({\n",
    "        'Name': info['Name'].values,\n",
    "        'Cycle': info['i'].values,\n",
    "        'Hands': info['hands'].values,\n",
    "        'Actual_Label': y_test.values,\n",
    "        'Predicted_Label': y_pred\n",
    "    })\n",
    "\n",
    "    new_data = new_data.sort_values(by='Name')\n",
    "    new_data['Is_Correct'] = new_data['Actual_Label'] == new_data['Predicted_Label']\n",
    "    new_data.to_csv(f\"F:\\\\All data\\\\Patient_Signal\\\\UTest\\\\{filename}.csv\", index=False, encoding='utf-8-sig')\n",
    "    print(f\"Results saved to {filename}.csv\")\n",
    "\n",
    "    # 將最終的 Actual_Label 和 Predicted_Label 的總結結果保存\n",
    "    final_summary = new_data.groupby('Name').agg(\n",
    "    Actual_0_Count=('Actual_Label', lambda x: (x == 0).sum()),\n",
    "    Actual_1_Count=('Actual_Label', lambda x: (x == 1).sum()),\n",
    "    Predicted_0_Count=('Predicted_Label', lambda x: (x == 0).sum()),\n",
    "    Predicted_1_Count=('Predicted_Label', lambda x: (x == 1).sum())\n",
    "    ).reset_index()\n",
    "\n",
    "    # 判斷總體的預測結果\n",
    "    final_summary['Predicted_Label'] = final_summary.apply(lambda row: 0 if row['Predicted_0_Count'] > row['Predicted_1_Count'] else 1, axis=1)\n",
    "    final_summary['Actual_Label'] = final_summary.apply(lambda row: 0 if row['Actual_0_Count'] > row['Actual_1_Count'] else 1, axis=1)\n",
    "\n",
    "    # 保存總結至 CSV\n",
    "    final_summary.to_csv(f\"F:\\\\All data\\\\Patient_Signal\\\\UTest\\\\{filename}_Final.csv\", index=False, encoding='utf-8-sig')\n",
    "    print(f\"Results saved to {filename}_Final.csv\")\n",
    "\n",
    "    \n",
    "    conf_matrix = confusion_matrix(final_summary['Actual_Label'], final_summary['Predicted_Label'])\n",
    "    plot_confusion_matrix(conf_matrix, title='Final Confusion Matrix')\n",
    "    metrics = calculate_metrics(conf_matrix)\n",
    "    print(\"Final Metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 SVM 模型\n",
    "def train_svm(X_train, y_train, X_test, y_test, X_columns):\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['linear'],\n",
    "        'class_weight': ['balanced']\n",
    "    }\n",
    "\n",
    "    svm_grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "    svm_grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = svm_grid_search.best_estimator_\n",
    "    best_params = svm_grid_search.best_params_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    metrics = calculate_metrics(conf_matrix)\n",
    "\n",
    "    feature_importance = np.abs(best_model.coef_[0])\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X_columns,\n",
    "        'Importance': feature_importance\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "        # 預測測試集\n",
    "\n",
    "    print(\"最佳參數:\", best_params)\n",
    "    print(\"特徵重要性排序：\\n\", feature_importance_df)\n",
    "\n",
    "    return best_model, metrics, conf_matrix, y_pred, feature_importance_df\n",
    "\n",
    "\n",
    "# SVM\n",
    "svm_model, svm_metrics, svm_conf_matrix, svm_y_pred, feature_importance_df = train_svm(X_train, y_train, X_test, y_test, X.columns)\n",
    "plot_confusion_matrix(svm_conf_matrix, title='SVM Confusion Matrix')\n",
    "print(\"SVM Metrics:\", svm_metrics)\n",
    "save_results_to_csv('SVM_Results', info_test, y_test, svm_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 KNN 模型\n",
    "def train_knn(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    }\n",
    "\n",
    "    knn_grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "    knn_grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = knn_grid_search.best_estimator_\n",
    "    best_params = knn_grid_search.best_params_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    metrics = calculate_metrics(conf_matrix)\n",
    "\n",
    "    # 特徵重要性 - 基於相關性分析（例如皮爾森相關係數）\n",
    "    feature_importance = np.abs(np.corrcoef(X_train.T, y_train.values, rowvar=True)[:-1, -1])\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': feature_importance\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "        # 預測測試集\n",
    "\n",
    "    print(\"最佳參數:\", best_params)\n",
    "    print(\"特徵重要性排序：\\n\", feature_importance_df)\n",
    "\n",
    "    return best_model, metrics, conf_matrix, y_pred\n",
    "\n",
    "# KNN\n",
    "knn_model, knn_metrics, knn_conf_matrix, knn_y_pred = train_knn(X_train, y_train, X_test, y_test)\n",
    "plot_confusion_matrix(knn_conf_matrix, title='KNN Confusion Matrix')\n",
    "print(\"KNN Metrics:\", knn_metrics)\n",
    "save_results_to_csv('KNN_Results', info_test, y_test, knn_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 Random Forest 模型\n",
    "def train_rf(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'class_weight': ['balanced']\n",
    "    }\n",
    "\n",
    "    rf_grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "    rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = rf_grid_search.best_estimator_\n",
    "    best_params = rf_grid_search.best_params_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    metrics = calculate_metrics(conf_matrix)\n",
    "\n",
    "        # 特徵重要性 - Random Forest 原生支援\n",
    "    feature_importance = best_model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': feature_importance\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    print(\"最佳參數:\", best_params)\n",
    "    print(\"特徵重要性排序：\\n\", feature_importance_df)\n",
    "    \n",
    "    return best_model, metrics, conf_matrix, y_pred\n",
    "\n",
    "# Random Forest\n",
    "rf_model, rf_metrics, rf_conf_matrix, rf_y_pred = train_rf(X_train, y_train, X_test, y_test)\n",
    "plot_confusion_matrix(rf_conf_matrix, title='Random Forest Confusion Matrix')\n",
    "print(\"Random Forest Metrics:\", rf_metrics)\n",
    "save_results_to_csv('RF_Results', info_test, y_test, rf_y_pred)\n",
    "# 輸出結果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
