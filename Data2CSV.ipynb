{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import os\n",
    "import openpyxl \n",
    "from scipy.integrate import simps\n",
    "import adi\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Python\\PPG\\All data\\Patient_Signal\\PPG.csv已刪除\n",
      "F:\\Python\\PPG\\All data\\Patient_Signal\\D2.csv已刪除\n"
     ]
    }
   ],
   "source": [
    "font_path = 'C:\\\\Windows\\\\Fonts\\\\simsun.ttc'  # 宋體\n",
    "font_prop = FontProperties(fname=font_path)\n",
    "\n",
    "npy = 'no' #! 是否儲存npy檔\n",
    "graph = ['break', 'break', 'break']   # 是否要畫圖['PPG', 'D1', 'D2']\n",
    "data = 'Patient'    #要用病患還是正常人資料\n",
    "\n",
    "if data == 'Patient':\n",
    "    data_file = 'F:\\\\Python\\\\PPG\\\\All data\\\\Patient_Signal'\n",
    "    graph_file = 'F:\\\\Python\\\\PPG\\\\All data\\\\Patient_Signal\\\\graph'\n",
    "elif data == 'Normal':\n",
    "    data_file = 'F:\\\\Python\\\\PPG\\\\All data\\\\Normal_Signal'\n",
    "    graph_file = 'F:\\\\Python\\\\PPG\\\\All data\\\\Normal_Signal\\\\graph'\n",
    "\n",
    "bad_graph = 'F:\\\\Python\\\\PPG\\\\All data\\\\Bad_Graph'\n",
    "\n",
    "PPG_path = f'{data_file}\\\\PPG.csv'\n",
    "D2_path = f'{data_file}\\\\D2.csv'\n",
    "\n",
    "#刪除指定CSV檔\n",
    "def delete_csv(file):\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(f'{file}已刪除')\n",
    "    else:\n",
    "        print(f'{file}不存在')\n",
    "\n",
    "delete_csv(PPG_path)\n",
    "delete_csv(D2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter(DataL, DataR, cut_low, cut_high, sample_rate, order):\n",
    "    nyqs = sample_rate * 0.5\n",
    "    H_cut = cut_high / nyqs\n",
    "    L_cut = cut_low / nyqs\n",
    "    sos = signal.butter(order, [L_cut, H_cut], analog=False, btype='bandpass', output='sos')\n",
    "    Filter_Left = signal.sosfiltfilt(sos, DataL)\n",
    "    Filter_Right = signal.sosfiltfilt(sos, DataR)\n",
    "    return Filter_Left, Filter_Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bassel(DataL, DataR, cut_low, cut_high, sample_rate, order):\n",
    "    #貝塞爾\n",
    "    nyqs = sample_rate * 0.5\n",
    "    H_cut = cut_high / nyqs\n",
    "    L_cut = cut_low / nyqs\n",
    "    sos=signal.bessel(order, [L_cut, H_cut] ,  btype='bandpass',  analog=False,  output='sos')\n",
    "    Filter_Left = signal.sosfiltfilt(sos,  DataL) \n",
    "    Filter_Right = signal.sosfiltfilt(sos,  DataR) \n",
    "\n",
    "    return Filter_Left, Filter_Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peak(Filter_Data):\n",
    "    valley_x, valley_y = find_peaks(Filter_Data * -1, height=0, distance=500)\n",
    "    cardiac_cycle = np.diff(valley_x)\n",
    "    peaks_x, peaks_y = find_peaks(Filter_Data, height=0, distance=500)\n",
    "    peaks_y = peaks_y['peak_heights']\n",
    "    valley_y = valley_y['peak_heights']\n",
    "    return peaks_x, peaks_y, valley_x, valley_y, cardiac_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(Data, Level, values=[]):\n",
    "    result = np.gradient(Data)\n",
    "\n",
    "    if Level == 0:\n",
    "        values.append(Data)\n",
    "        return 0\n",
    "    else:\n",
    "        values.append(Data)\n",
    "        return derivative(result, Level - 1, values)\n",
    "    \n",
    "def process_wave(cycle):\n",
    "    values = []\n",
    "    derivative(cycle, 3, values)\n",
    "    values = np.array(values)\n",
    "    origin, derivative_1, derivative_2, derivative_3 = values\n",
    "    derivative_1 = derivative_1 * 50\n",
    "    derivative_2 = derivative_2 * 5000\n",
    "    derivative_3 = derivative_3 * 100000\n",
    "\n",
    "    return [derivative_1, derivative_2, derivative_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Path(path):\n",
    "\n",
    "    File_path = []\n",
    "\n",
    "    #find all Data_file path \n",
    "    for root,  subfolders,  filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.txt'):\n",
    "                continue\n",
    "            filepath = root +'/'+ filename\n",
    "            new_filepath = filepath.replace(\"\\\\\", \"/\")\n",
    "            File_path.append(new_filepath)\n",
    "\n",
    "    return File_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Imformation(path):\n",
    "    test=path.split('/')\n",
    "    Name = test[-3]\n",
    "    State_check = test[-4]\n",
    "    if State_check =='易堵':\n",
    "        State = '0'\n",
    "    else: \n",
    "        State = '1'\n",
    "\n",
    "    file_name = test[len(test)-1]\n",
    "    name_check = file_name.find('R')\n",
    "    if name_check != -1:\n",
    "        hands = 'Right'\n",
    "    else:\n",
    "        hands = 'Left'\n",
    "    \n",
    "    imformation =[Name, hands, State]\n",
    "\n",
    "    return imformation, Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ppg(waveform, feature, Name, i, hands):\n",
    "    if graph[0] != 'break':\n",
    "        x = np.linspace(0, len(waveform), len(waveform))\n",
    "        plt.figure(figsize=(5, 3))\n",
    "        plt.plot(waveform, label='PPG')\n",
    "        plt.plot(x[feature], waveform[feature], 'r.', label='peak')\n",
    "        plt.title(f'{Name} PPG signal {i} {hands}', fontproperties=font_prop)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        if graph[1] == 'show':\n",
    "            plt.show()\n",
    "        elif graph[1] == 'save':\n",
    "            plt.savefig(f'{graph_file}\\\\{Name}, {i + 1}th.jpg')\n",
    "\n",
    "        plt.close('all')\n",
    "\n",
    "def calculate_PPG(waveform, feature, Name, i, hands):\n",
    "    peak, B10 = find_peaks(waveform, height=0.3, distance=500)\n",
    "    if len(peak) < 2:\n",
    "        return 0, None\n",
    "    B1 = peak[1]    #! 之後補註解\n",
    "    B10 = B10['peak_heights'][1]\n",
    "    B2 = (waveform[feature[5]] + waveform[feature[11]]) / 2\n",
    "    valley, _ = find_peaks(-waveform, height=-0.3, distance=500)\n",
    "    if len(valley) < 2:\n",
    "        return 0, None\n",
    "    B3 = valley[1] - valley[0]\n",
    "    y_section = np.abs(waveform[valley[0]:valley[1]+1])\n",
    "    B5 = np.trapz(y_section, dx=1)\n",
    "    B6 = peak[1] - peak[0]\n",
    "    B7 = valley[-1] - peak[-1]\n",
    "    Delta_T = B2 - B1\n",
    "    calculate_feature = np.array([B1, B2, B3, B5, B6, B7, B10, Delta_T])\n",
    "    #print(calculate_feature)\n",
    "    plot_ppg(waveform, feature, Name, i, hands)\n",
    "\n",
    "    \n",
    "    if len(calculate_feature) == 8:\n",
    "        return 1, calculate_feature\n",
    "    else:\n",
    "        return 0, None\n",
    "\n",
    "def print_features(Name, i, hand, csv_path):\n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv(csv_path, header=None)\n",
    "\n",
    "    # Construct the key from Name, i, and hand to match the first column\n",
    "    key = f\"{Name}, {i}th {hand} d2\"\n",
    "\n",
    "    # Search for the matching row in the first column\n",
    "    matching_row = data[data[0] == key]\n",
    "\n",
    "    if not matching_row.empty:\n",
    "        print(f\"Features for {key}:\")\n",
    "        print(matching_row.iloc[0, 1:].values)  # Print feature values (ignoring the first column)\n",
    "        return matching_row.iloc[0, 1:].values.tolist()\n",
    "    else:\n",
    "        print(f\"No matching features found for {key}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_d1(waveform, Feature, Name, i, hands):\n",
    "    if graph[1] != 'break':\n",
    "        x = np.linspace(0, len(waveform), len(waveform))\n",
    "        plt.figure()\n",
    "        plt.plot(waveform)\n",
    "        plt.plot(x[Feature], waveform[Feature], '*', label='Peak')\n",
    "        plt.title(f'{Name}, {i + 1}th Left_Right',fontproperties=font_prop)\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        if graph[1] == 'show':\n",
    "            plt.show()\n",
    "        elif graph[1] == 'save':\n",
    "            plt.savefig(f'{graph_file}\\\\{Name}, {i + 1}th d1.jpg')\n",
    "\n",
    "        plt.close('all')\n",
    "\n",
    "def calculate_d1(waveform, Name, i, graph, hands):\n",
    "    \n",
    "    d1_peaks, B8 = find_peaks(waveform, height=0, distance=800)\n",
    "    if len(d1_peaks) < 2:\n",
    "        return 0, None\n",
    "    B4 = d1_peaks[1] - d1_peaks[0]\n",
    "    B8 = B8['peak_heights']\n",
    "\n",
    "    D1_feature = np.array([B4, B8[1]])\n",
    "\n",
    "    if len(D1_feature) == 2:\n",
    "        return 1, D1_feature\n",
    "    else:\n",
    "        return 0, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_d2_feature(waveform, points):\n",
    "    points_y = np.zeros(6)\n",
    "    for i in range(6,12):\n",
    "        points_y[i-6] = waveform[i]\n",
    "    #print(points_y)\n",
    "    Ratio_BA = points_y[1] / points_y[0]\n",
    "    Ratio_CA = points_y[2] / points_y[0]\n",
    "    Ratio_DA = points_y[3] / points_y[0]\n",
    "    Ratio_BDCE_A = (points_y[1] - points_y[3] - points_y[2] - points_y[4]) / points_y[0]\n",
    "    Ratio_CDB_A = (points_y[2] + points_y[3] - points_y[4]) / points_y[0]\n",
    "    \n",
    "    features = [Ratio_BA, Ratio_CA, Ratio_DA, Ratio_BDCE_A, Ratio_CDB_A]\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_d2(origin, derivative, Name, i, Feature, hands, locate):\n",
    "    if graph[2] != 'break':\n",
    "        x = np.linspace(0, len(derivative[1]), len(derivative[1]))\n",
    "        plt.figure()\n",
    "        \n",
    "        plt.plot(origin)\n",
    "        plt.plot(derivative[1])\n",
    "        plt.plot(x[Feature], derivative[1][Feature], '*', label='Peak')\n",
    "        plt.title(f'{Name}, {i + 1}th {hands}',fontproperties=font_prop)\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        if graph[2] == 'show':\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(f'{locate}\\\\{Name}, {i + 1}th {hands} d2.jpg')\n",
    "        \n",
    "        plt.close('all')\n",
    "\n",
    "def calculate_d2(origin, derivative, Name, i, hands):\n",
    "    TDPPG_x = np.where(np.diff(np.sign(derivative[2])))[0]\n",
    "    # 設置最小距離（例如，至少 10 個數據點）\n",
    "    min_distance = 30\n",
    "\n",
    "    def filter_by_distance(zero_crossings, min_distance):\n",
    "        filtered_crossings = []\n",
    "        last_index = -min_distance  # 初始化為一個遠距離的負數\n",
    "        \n",
    "        for index in zero_crossings:\n",
    "            if index - last_index >= min_distance:\n",
    "                filtered_crossings.append(index)\n",
    "                last_index = index\n",
    "        \n",
    "        return np.array(filtered_crossings)\n",
    "\n",
    "    # 過濾零點\n",
    "    TDPPG_x = filter_by_distance(TDPPG_x, min_distance)\n",
    "\n",
    "    closest_indices = []\n",
    "\n",
    "    a_point = np.array(find_peaks(derivative[1], height=0.6, distance=900)[0])\n",
    "\n",
    "\n",
    "    for num in a_point:\n",
    "        differences = np.abs(TDPPG_x - num)\n",
    "        closest_index = np.argmin(differences)\n",
    "        closest_indices.append(closest_index)\n",
    "    if len(closest_indices) < 2:  #判斷抓到兩個周期\n",
    "        plot_d2(origin, derivative, Name, i, TDPPG_x, hands, bad_graph)\n",
    "        #print(f'{Name}, {i + 1}th {hands} cant find the feature')\n",
    "        return 0, None, None\n",
    "    else:\n",
    "        TDPPG_x_new = TDPPG_x[closest_indices[0]:closest_indices[0]+6]\n",
    "        TDPPG_x_new = np.append(TDPPG_x_new, TDPPG_x[closest_indices[1]:closest_indices[1]+6])\n",
    "        if TDPPG_x_new[6] - TDPPG_x_new[5] < TDPPG_x_new[6] * 0.3 or len(TDPPG_x_new) != 12: #判斷是否抓錯feature\n",
    "            plot_d2(origin, derivative, Name, i, TDPPG_x_new, hands, bad_graph)\n",
    "            return 0, None, None\n",
    "\n",
    "\n",
    "    if graph =='show':\n",
    "        plot_d2(origin,derivative, Name, i, TDPPG_x_new, hands, graph_file)\n",
    "        print(TDPPG_x_new)\n",
    "    else:\n",
    "        D2_feature = calculate_d2_feature(derivative[1], TDPPG_x_new)\n",
    "        return 1, TDPPG_x_new, D2_feature\n",
    "    \n",
    "    return 0, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteCSV(feature, file_path, i, hands, imformation):\n",
    "    \n",
    "    # if imformation[2] == '0' and imformation[1] != hands:\n",
    "    #     change = '1'\n",
    "    #     new_data = pd.DataFrame([[f\"{imformation[0]}\"] + [i + 1] + [f\"{imformation[1]}\"] + [f\"{hands}\"] + [f\"{change}\"] + feature.tolist()])\n",
    "    # else:\n",
    "    new_data = pd.DataFrame([[f\"{imformation[0]}\"] + [i + 1] + [f\"{imformation[1]}\"] + [f\"{hands}\"] + [f\"{imformation[2]}\"] + feature.tolist()])\n",
    "\n",
    "    try:\n",
    "        # 使用 'utf-8-sig' 編碼，以避免中文亂碼問題\n",
    "        with open(file_path, 'a', newline='', encoding='utf-8-sig') as f:\n",
    "            new_data.to_csv(f, index=False, header=False)\n",
    "    except FileNotFoundError:\n",
    "        # 如果檔案不存在，直接創建新檔案並寫入\n",
    "        new_data.to_csv(file_path, index=False, header=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_wave(waveform, i, hands, imformation, target_length=2000): # type: ignore\n",
    "    quilty = 1\n",
    "\n",
    "    derivative = process_wave(waveform)\n",
    "\n",
    "    resized = signal.resample(waveform, target_length)\n",
    "    \n",
    "    for j in range(3):\n",
    "        derivative[j] = signal.resample(derivative[j], target_length)\n",
    "    \n",
    "    D2_quilty, D2_Point, D2_feature = calculate_d2(resized, derivative, imformation[0], i, hands) # type: ignore\n",
    "    if D2_quilty == 1:\n",
    "        D1_quailty, D1_feature = calculate_d1(derivative[0], D2_Point, imformation[0], i, hands)\n",
    "        quailty, PPG_feature = calculate_PPG(resized, D2_Point, imformation[0], i, hands)\n",
    "        Classfication_feature = np.hstack((PPG_feature, D1_feature, D2_feature)) # type: ignore\n",
    "        if D1_quailty == 1 and quailty == 1:\n",
    "            WriteCSV(D2_Point, D2_path, i, hands, imformation)\n",
    "            WriteCSV(Classfication_feature, PPG_path, i, hands, imformation)\n",
    "            \n",
    "            if npy == 'save':\n",
    "                np.save(f'{data_file}\\\\{imformation[0]}, {i + 1}th {hands}.npy', resized)\n",
    "                np.save(f'{data_file}\\\\{imformation[0]}, {i + 1}th {hands} d1.npy', derivative[0])\n",
    "                np.save(f'{data_file}\\\\{imformation[0]}, {i + 1}th {hands} d2.npy', derivative[1])\n",
    "\n",
    "    elif npy == 'save':\n",
    "        np.save(f'{data_file}\\\\bad signal\\\\{imformation[0]}, {i + 1}th {hands}.npy', resized)\n",
    "        np.save(f'{data_file}\\\\bad signal\\\\{imformation[0]}, {i + 1}th {hands} d1.npy', derivative[0])\n",
    "        np.save(f'{data_file}\\\\bad signal\\\\{imformation[0]}, {i + 1}th {hands} d2.npy', derivative[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(): #!for folder data\n",
    "    channel1_id = 2\n",
    "    channel2_id = 4\n",
    "    record_id = 1\n",
    "\n",
    "    if data == 'Normal':\n",
    "        File_path = Find_Path(\"F:\\\\正常人Data\") #!正常人\n",
    "    elif data == 'Patient':\n",
    "        File_path = Find_Path(\"F:\\\\Python\\\\PPG\\\\病患資料\") #!病患\n",
    "    print('找到資料筆數', len(File_path))\n",
    "\n",
    "    df_c = pd.DataFrame()\n",
    "    for j, path in tqdm(enumerate(File_path), total=len(File_path), desc='Processing'):\n",
    "        Data = adi.read_file(path)\n",
    "\n",
    "        Right = Data.channels[channel1_id - 1].get_data(record_id)\n",
    "        Left = Data.channels[channel2_id - 1].get_data(record_id)\n",
    "\n",
    "        Filter_Left,Filter_Right = butter(Left, Right, 0.5, 9, 1000, 4)\n",
    "\n",
    "        L_wave = Filter_Left[20000:300000] * 10\n",
    "        R_wave = Filter_Right[20000:300000] * 10\n",
    "\n",
    "        L_valley_x, L_valley_y = find_peaks(L_wave * -1, height=0, distance=150)\n",
    "        R_valley_x, R_valley_y = find_peaks(R_wave * -1, height=0, distance=150)\n",
    "\n",
    "        L_valley_y = L_valley_y['peak_heights']\n",
    "        R_valley_y = R_valley_y['peak_heights']\n",
    "\n",
    "        if data == 'Normal':\n",
    "            imformation,Name = get_Imformation(path) #!正常人\n",
    "        elif data == 'Patient':\n",
    "            imformation,Name = get_Imformation(path) #!病患\n",
    "\n",
    "        if len(L_valley_x) > len(R_valley_x): #找最小的cycle\n",
    "            min_cycle = len(R_valley_x)\n",
    "        else:\n",
    "            min_cycle = len(L_valley_x)\n",
    "        \n",
    "        for i in range(0,min_cycle - 2,2):\n",
    "            L_cycle = L_wave[L_valley_x[i]:L_valley_x[i + 2]] #two cycle\n",
    "\n",
    "            L_peaks_x, L_peaks_y = find_peaks(L_cycle, height=0, distance=500)\n",
    "            L_peaks_y = L_peaks_y['peak_heights']\n",
    "\n",
    "            R_cycle = R_wave[L_valley_x[i]:L_valley_x[i + 2]]\n",
    "\n",
    "            R_peaks_x, R_peaks_y = find_peaks(R_cycle, height=0, distance=500)\n",
    "            R_peaks_y = R_peaks_y['peak_heights']\n",
    "\n",
    "            if len(L_cycle) < 1100 or len(L_peaks_y) != 2 or len(R_peaks_y) != 2 or len(R_cycle) < 1100:\n",
    "                continue\n",
    "\n",
    "            if L_peaks_y[0] < 0.5:\n",
    "                L_cycle *= 0.5 / L_peaks_y[0]\n",
    "                L_peaks_y[0] = 0.5\n",
    "                L_peaks_y[1] = 0.5\n",
    "\n",
    "            if R_peaks_y[0] < 0.5:\n",
    "                R_cycle *= 0.5 / R_peaks_y[0]\n",
    "                R_peaks_y[0] = 0.5\n",
    "                R_peaks_y[1] = 0.5\n",
    "            resize_wave(L_cycle, i, 'Left', imformation, 2000 )\n",
    "            resize_wave(R_cycle, i, 'Right', imformation, 2000 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到資料筆數 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 64/64 [00:35<00:00,  1.82it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
